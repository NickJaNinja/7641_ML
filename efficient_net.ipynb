{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Instructions\n",
        "\n",
        "This file is meant to be run from Google Colab to run properly.\n",
        "\n",
        "Steps to get this working:\n",
        "1. Go to your Kaggle Account, and get a \"New API Token\" which installs a json file.\n",
        "2. Upload this file into Colab under root/.kaggle (need to toggle visibility of hidden directories to see this)"
      ],
      "metadata": {
        "id": "co5XQ-oUMZYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 /root/.kaggle/kaggle.json\n",
        "! kaggle competitions download state-farm-distracted-driver-detection --force\n",
        "! unzip state-farm-distracted-driver-detection.zip"
      ],
      "metadata": {
        "id": "GLia7xVGdmg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "IWdrmgU2dgED"
      },
      "outputs": [],
      "source": [
        "import os, csv\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers \n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "\n",
        "TRAIN_DIR = './imgs/train'\n",
        "TEST_DIR = './imgs/test'\n",
        "\n",
        "NUM_CLASSES = 10\n",
        "IMG_SIZE = 224  # EfficientNet was trained on (224,224,3) images\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCH = 10\n",
        "VALIDATION_SPLIT = 0.2\n",
        "MODEL_NAME = 'ResNet50'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "FAmv38DadgEI"
      },
      "outputs": [],
      "source": [
        "def build_dataset():\n",
        "    train_data = tf.keras.utils.image_dataset_from_directory(\n",
        "        TRAIN_DIR, \n",
        "        label_mode='categorical', \n",
        "        image_size=(IMG_SIZE, IMG_SIZE), \n",
        "        batch_size=64,\n",
        "        seed=0, # Needed when using validation split\n",
        "        validation_split=VALIDATION_SPLIT,\n",
        "        subset='training'\n",
        "    )\n",
        "    test_data = tf.keras.utils.image_dataset_from_directory(\n",
        "        TEST_DIR, \n",
        "        labels=None, \n",
        "        image_size=(IMG_SIZE, IMG_SIZE), \n",
        "        batch_size=64, \n",
        "        shuffle=False # Sorts alphabetically by filename\n",
        "    )\n",
        "\n",
        "    return (train_data, test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "rrPbB81CdgEH"
      },
      "outputs": [],
      "source": [
        "img_augmentation = Sequential(\n",
        "    [\n",
        "        layers.RandomRotation(factor=0.15),\n",
        "        layers.RandomContrast(factor=0.1),\n",
        "    ],\n",
        "    name='img_augmentation',\n",
        ")\n",
        "\n",
        "def build_model(num_classes, weights=None):\n",
        "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    x = img_augmentation(inputs)\n",
        "    model = ResNet50(include_top=True, input_tensor=x, weights=None, classes=num_classes)\n",
        "\n",
        "    if weights is not None:\n",
        "      # Using pretrained weights, so let's finetune the top layers\n",
        "      max_pooling = layers.MaxPooling2D(pool_size=(2, 2))\n",
        "      batch_norm = layers.BatchNormalization()\n",
        "      dropout = layers.Dropout(0.2, name='top_dropout')\n",
        "      fc_out = layers.Dense(num_classes, activation='softmax', name='prediction')\n",
        "\n",
        "      model = ResNet50(include_top=False, input_tensor=x, weights=weights)\n",
        "      model.trainable = False # Freeze layers\n",
        "\n",
        "      # Add top layers (not frozen)\n",
        "      x = max_pooling(model.output)\n",
        "      x = batch_norm(x)\n",
        "      x = dropout(x)\n",
        "      outputs = fc_out(x)\n",
        "      \n",
        "      model = tf.keras.Model(inputs, outputs, name=MODEL_NAME)\n",
        "    \n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
        "    model.compile(optimizer=optimizer, \n",
        "                  loss='categorical_crossentropy', \n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "def save_output_csv(filename, y_pred):\n",
        "  output_path = f'{filename}.csv'\n",
        "  image_names = sorted([img_name for img_name in os.listdir(TEST_DIR)])\n",
        "\n",
        "  with open(output_path, 'w', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        title_row = ['img'] + [f'c{i}' for i in range(NUM_CLASSES)]\n",
        "        writer.writerow(title_row, )\n",
        "        for i in range(len(image_names)):\n",
        "            name = [image_names[i]]\n",
        "            data = list(map(str, y_pred[i]))\n",
        "            row = name + data\n",
        "            writer.writerow(row)\n",
        "\n",
        "  files.download(output_path)"
      ],
      "metadata": {
        "id": "Zok_IBtOhgmz"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxhrC8M4dgEI"
      },
      "outputs": [],
      "source": [
        "train_data, test_data = build_dataset()\n",
        "\n",
        "model = build_model(NUM_CLASSES, weights=None)\n",
        "\n",
        "history = model.fit(train_data, \n",
        "                    epochs=NUM_EPOCH, \n",
        "                    batch_size=BATCH_SIZE)\n",
        "y_pred = model.predict(test_data, batch_size=BATCH_SIZE, verbose=1)\n",
        "\n",
        "save_output_csv(MODEL_NAME, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_accuracy(hist):\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def plot_loss(hist):\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "plot_accuracy(history)"
      ],
      "metadata": {
        "cellView": "code",
        "id": "qtok3YKU796A"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
    },
    "kernelspec": {
      "display_name": "Python 3.9.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "efficient_net.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}